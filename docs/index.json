[{"content":"最近写了一个bash脚本，可以方便地切换CUDA版本的同时不会把你的PATH变得很大，在多个不同cuda版本编译的conda环境中切换非常方便，分享一下：\n创建cuda_switcher.sh:\n# ~/cuda-switcher/switch_cuda.sh #!/bin/bash if [ -z \u0026#34;$1\u0026#34; ]; then echo \u0026#34;Usage: source switch_cuda.sh \u0026lt;version\u0026gt;\u0026#34; echo \u0026#34;Example: source switch_cuda.sh 11.2\u0026#34; return 1 fi CUDA_VERSION=$1 CUDA_PATH=\u0026#34;/usr/local/cuda-$CUDA_VERSION\u0026#34; if [ ! -d \u0026#34;$CUDA_PATH\u0026#34; ]; then echo \u0026#34;CUDA version $CUDA_VERSION not found at $CUDA_PATH\u0026#34; return 1 fi # Remove any existing CUDA paths from PATH and LD_LIBRARY_PATH export PATH=$(echo $PATH | sed -e \u0026#39;s|/usr/local/cuda-[^/]*||g\u0026#39; -e \u0026#39;s|::|:|g\u0026#39; -e \u0026#39;s|^:||\u0026#39; -e \u0026#39;s|:$||\u0026#39;) export LD_LIBRARY_PATH=$(echo $LD_LIBRARY_PATH | sed -e \u0026#39;s|/usr/local/cuda-[^/]*||g\u0026#39; -e \u0026#39;s|::|:|g\u0026#39; -e \u0026#39;s|^:||\u0026#39; -e \u0026#39;s|:$||\u0026#39;) # Add the new CUDA paths export CUDA_HOME=$CUDA_PATH export PATH=$CUDA_HOME/bin:$PATH export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH echo \u0026#34;Switched to CUDA $CUDA_VERSION\u0026#34; 使用：\n首先确定你的CUDA_VERSION，此脚本不会检测你电脑上是否存在这一版本，不过输错了也不怕，再输一次对的就好了。 然后运行bash cuda_switcher.sh $YOUR_CUDA_VERSION ","permalink":"https://net-maker.github.io/post/cuda_switcher/","summary":"最近写了一个bash脚本，可以方便地切换CUDA版本的同时不会把你的PATH变得很大，在多个不同cuda版本编译的conda环境中切换非常方便，分享一下：\n创建cuda_switcher.sh:\n# ~/cuda-switcher/switch_cuda.sh #!/bin/bash if [ -z \u0026#34;$1\u0026#34; ]; then echo \u0026#34;Usage: source switch_cuda.sh \u0026lt;version\u0026gt;\u0026#34; echo \u0026#34;Example: source switch_cuda.sh 11.2\u0026#34; return 1 fi CUDA_VERSION=$1 CUDA_PATH=\u0026#34;/usr/local/cuda-$CUDA_VERSION\u0026#34; if [ ! -d \u0026#34;$CUDA_PATH\u0026#34; ]; then echo \u0026#34;CUDA version $CUDA_VERSION not found at $CUDA_PATH\u0026#34; return 1 fi # Remove any existing CUDA paths from PATH and LD_LIBRARY_PATH export PATH=$(echo $PATH | sed -e \u0026#39;s|/usr/local/cuda-[^/]*||g\u0026#39; -e \u0026#39;s|::|:|g\u0026#39; -e \u0026#39;s|^:||\u0026#39; -e \u0026#39;s|:$||\u0026#39;) export LD_LIBRARY_PATH=$(echo $LD_LIBRARY_PATH | sed -e \u0026#39;s|/usr/local/cuda-[^/]*||g\u0026#39; -e \u0026#39;s|::|:|g\u0026#39; -e \u0026#39;s|^:||\u0026#39; -e \u0026#39;s|:$||\u0026#39;) # Add the new CUDA paths export CUDA_HOME=$CUDA_PATH export PATH=$CUDA_HOME/bin:$PATH export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH echo \u0026#34;Switched to CUDA $CUDA_VERSION\u0026#34; 使用：","title":"CUDA_switcher"},{"content":"前言 通过一个月以来高强度的熬夜，终于是与xinyang一起将GGavatar所有内容完成了。GGavatar是我和他在公司相遇后一起从零构建的一个作品，我们主要参考gaussianavatars、flashavatar、slpattingavatar这三篇文章，进一步增加了基于高斯的avatar的性能，这篇文章的创作总共经历了三个月，与我第一篇匆匆完成的水文形成了鲜明的对比，我想这大概才是一篇文章该有的工作量吧。经历的越多，越觉得自己渺小，所以写下这篇文章，时刻提醒自己保持认真严谨的态度对待科研。\n第一篇水文：HC-NeRF 在代码中挣扎 23年暑假，我在家中冥思苦想，却始终解决不了当时想针对instant-NGP做的改进\u0026ndash;将采样从四边形模式变成正三角形模式（这个idea在23年底被arxiv上的优秀同学开发了）。戴老师也多次想要针对这一问题给予我一定的帮助，但是奈何CUDA实现的哈希表以及整个nerf流程，对当时的我来说实在是难以看懂并解决，且问题出在另一个几千行代码的文件中。\n经历了科研中第一次滑铁卢，我带着不舍放弃了这一持续了半年以上的项目，转而接过戴老师给我的任务，缝合两篇文章水个成果，为之后升学提供一些帮助。此刻的我虽然心情不太好，但是把斗志放在了这一个水成果的目标上，我想，我大概是已经入门了科研，水一篇成果应该是不难的。\n然而，科研路上一帆风顺的情景并不多，尽管我每天不论睡觉还是清醒，脑袋里都一直是这两个模型，但是缝合后的结果并不work。并且几个很小的bug，就卡住了我非常久的时间，还好戴老师的师弟熟悉代码，为我指出了这些细节部分的问题。（这里便看出注重细节是多么重要）然而，解决了bug后的结果仍然没有足够的说服力，只是与baseline持平。性能几乎没有任何提升，这个时候已经来到了九月底，三个月的时间并没有做出什么成果，这令我有些失落。当时我想，我是不是没什么科研天赋？于是我跑去考研，八十多天的学习，虽然枯燥，但是每天都有一定的收获，也挺充实。当然，复习时间太短，总归是竞争不过其他人的，只能遗憾落榜。（这里还是不明智，若是坚持多一点，说不定能在年前就做出成果）\n在24年年后，戴老师呼唤我重回实验室，我也欣然接受了，毕竟自己烂尾的项目，还是得自己填完。在没有一线写代码的空档期，我依旧关注着前沿文章（包括3DGS的问世，它令我感到激动），所以这次我并没有急着去代码中胡乱调参，而是调研了更多的文献，这让我对科研方法有了更多的认识，对之前要缝合的两篇文献，也有了更深的理解。我想，这时候可能才算是真正的刚刚入门吧。\n在之后与戴老师的高强度会议中，我又认识到了沟通的重要性，我才发现讨论了那么久的模型，我脑海中的pipeline和他脑海中的居然有偏差，他思考之后，认为我这个想法更有新颖性，我又朝着提升效果的目标继续前进。有了更加谨慎的经验，同时对于git等工具的使用也更加轻车熟路，一个月之后我自己加了一些idea，提升了总体的性能，同时有一个样本效果大幅提升，做科研这么久，终于也是喜笑颜开一次。在与戴老师沟通完idea之后，他觉得我这个idea可以单独在其中一篇文章中做改进，并不需要强行缝合，说不定有更好的效果，试试也如此，戴老师也有了一定的行文思路，他决定带我投最近的ACM MM，并指导我写作。\n在写文中挣扎 在开始写作之前，我一直觉得代码才是最重要的，文章写起来顺理成章，但是细细品读之前参考的文章，才发现行文才是最体现科研功底的一项。如何讲好一个故事，通过什么启发，经过什么改进，通过实验怎么证明，突出了什么贡献，这都是我未曾考虑过的。当时的我只是单纯的刷榜，并没有太多其他思考，这也导致了我初稿几乎都是借鉴和GPT生成，后被戴老师全部弃用。写完初稿后，戴老师开始了他的修改，基于我的idea，他讲述了一个完全不同的科研探索过程，提出了他自己的一套理论，虽然都是完成了相同的任务，取得了相同的成果，但是换一个叙述方式之后，这篇文章已经完全不同了，文字当中充满了逻辑性，与原先的可以说是天壤之别。经过十几个夜晚的奋斗，我们完成了全文，并理清了思路，这当中由于我的粗心，多少会闹得戴老师烦心，但是他依旧耐心，为我解惑和指导，回想至此也是感激不尽，我也收益良多，不仅初步学会了写文章的所有流程，还获得了些科研思维。（当时好几天都是七八张4090租着跑实验，最后光速报销，财大气粗的感觉真爽。）\n提交了这一不算丰硕的成果到国际顶级会议，我无比激动，这一段经历也让我初步认识了一篇论文的从零到一，当然，多少有些飘飘然，多少有些膨胀。在实习期间，结识了xinyang，我们都对3DGS感兴趣，都在算法部做数字人，他邀请我跟他一起做高斯数字人的改进，我也是欣然接受。\nGGAvatar-新的磨练 在这之前，我对数字人已经非常熟悉了，在去年做科研的同时，我也高度参与了一位硕士生的毕业论文项目，为他完成了大部分代码和实验。主要就是关于三维人体重建的，对数字人的关注从22年就开始了，见过的工作较多，想着自己有一篇文章的经验，这下算是真正入门了，可以往数字人方向上走走了。\n代码上，已然是轻车熟路了，我能够为xinyang提供一些改进思路，并且确实是work的，虽然一些调参工作比较繁杂，但是代码上的工作只进行了一个月左右，就取得了很大的进步。我们开始写文章、选baseline做实验，与之前的流程类似。\n但是，此次做实验与HC-NeRF不同，HC-NeRF跑baseline很方便，公共数据集也比较多，但Avatar类工作没有太多公共数据集，需要大量的时间来复现baseline、修改代码以实现一些公共task、在这上面花的精力比文章主体模型还要多，同时还要进行大量的可视化对比，图表绘制，大量数据的对齐，在这么多繁杂的任务中，我的粗心更是时不时就将事情搞砸，比如渲染视频的帧乱了，或是FLAME的tracker出bug了，每一步都没有很好地去排查，导致错了才发现要从头再来，且当时没有很好地去反思，频频犯错。\n许多叙述上的词汇不到位、某个baseline渲染出来的角度没对齐，这些细节部分的问题，我总是忽略，导致作品最后显得粗糙，还好xinyang非常注重细节，帮我一起排查审核，不过确实实打实的影响了进度，这些错误其实可以不用犯，要么是原理问题没有钻研清楚，要么是单纯粗心大意，没有进一步检查，这里写下一些复盘后的感想，望与读者共勉：\n在完成多个阶段的任务时，要确保每一阶段都达到要求，不然牵一发而动全身，会浪费很多时间，特别是baseline的复现 对待baseline，不能轻视，我认为要将它的代码也看作研究中的一部分，好好研究，才不容易出错 制作对比图表时，很容易发现问题，发现后要顺藤摸瓜地去排查，而不是自圆其说，敷衍了事 在研究HC-NeRF时体会到的：不要只关注一个实验样本的结果，应该关注整体结果，并从指标中发现问题，这也是发现idea的好机会 最后，用心对待正在参与的每一个科研项目，切不可懒散 结语 本文章文字枯燥、叙述繁琐，读者能看到这里是我莫大荣幸。求学路上定有与我经历相似的朋友，若能在我这篇文章中获得些许经验，那本文也是有了意义，很多道理都是经历过后才能知行合一的，但是若能提前悟出，少走弯路，那是最好。\n","permalink":"https://net-maker.github.io/post/paper_thinking/","summary":"前言 通过一个月以来高强度的熬夜，终于是与xinyang一起将GGavatar所有内容完成了。GGavatar是我和他在公司相遇后一起从零构建的一个作品，我们主要参考gaussianavatars、flashavatar、slpattingavatar这三篇文章，进一步增加了基于高斯的avatar的性能，这篇文章的创作总共经历了三个月，与我第一篇匆匆完成的水文形成了鲜明的对比，我想这大概才是一篇文章该有的工作量吧。经历的越多，越觉得自己渺小，所以写下这篇文章，时刻提醒自己保持认真严谨的态度对待科研。\n第一篇水文：HC-NeRF 在代码中挣扎 23年暑假，我在家中冥思苦想，却始终解决不了当时想针对instant-NGP做的改进\u0026ndash;将采样从四边形模式变成正三角形模式（这个idea在23年底被arxiv上的优秀同学开发了）。戴老师也多次想要针对这一问题给予我一定的帮助，但是奈何CUDA实现的哈希表以及整个nerf流程，对当时的我来说实在是难以看懂并解决，且问题出在另一个几千行代码的文件中。\n经历了科研中第一次滑铁卢，我带着不舍放弃了这一持续了半年以上的项目，转而接过戴老师给我的任务，缝合两篇文章水个成果，为之后升学提供一些帮助。此刻的我虽然心情不太好，但是把斗志放在了这一个水成果的目标上，我想，我大概是已经入门了科研，水一篇成果应该是不难的。\n然而，科研路上一帆风顺的情景并不多，尽管我每天不论睡觉还是清醒，脑袋里都一直是这两个模型，但是缝合后的结果并不work。并且几个很小的bug，就卡住了我非常久的时间，还好戴老师的师弟熟悉代码，为我指出了这些细节部分的问题。（这里便看出注重细节是多么重要）然而，解决了bug后的结果仍然没有足够的说服力，只是与baseline持平。性能几乎没有任何提升，这个时候已经来到了九月底，三个月的时间并没有做出什么成果，这令我有些失落。当时我想，我是不是没什么科研天赋？于是我跑去考研，八十多天的学习，虽然枯燥，但是每天都有一定的收获，也挺充实。当然，复习时间太短，总归是竞争不过其他人的，只能遗憾落榜。（这里还是不明智，若是坚持多一点，说不定能在年前就做出成果）\n在24年年后，戴老师呼唤我重回实验室，我也欣然接受了，毕竟自己烂尾的项目，还是得自己填完。在没有一线写代码的空档期，我依旧关注着前沿文章（包括3DGS的问世，它令我感到激动），所以这次我并没有急着去代码中胡乱调参，而是调研了更多的文献，这让我对科研方法有了更多的认识，对之前要缝合的两篇文献，也有了更深的理解。我想，这时候可能才算是真正的刚刚入门吧。\n在之后与戴老师的高强度会议中，我又认识到了沟通的重要性，我才发现讨论了那么久的模型，我脑海中的pipeline和他脑海中的居然有偏差，他思考之后，认为我这个想法更有新颖性，我又朝着提升效果的目标继续前进。有了更加谨慎的经验，同时对于git等工具的使用也更加轻车熟路，一个月之后我自己加了一些idea，提升了总体的性能，同时有一个样本效果大幅提升，做科研这么久，终于也是喜笑颜开一次。在与戴老师沟通完idea之后，他觉得我这个idea可以单独在其中一篇文章中做改进，并不需要强行缝合，说不定有更好的效果，试试也如此，戴老师也有了一定的行文思路，他决定带我投最近的ACM MM，并指导我写作。\n在写文中挣扎 在开始写作之前，我一直觉得代码才是最重要的，文章写起来顺理成章，但是细细品读之前参考的文章，才发现行文才是最体现科研功底的一项。如何讲好一个故事，通过什么启发，经过什么改进，通过实验怎么证明，突出了什么贡献，这都是我未曾考虑过的。当时的我只是单纯的刷榜，并没有太多其他思考，这也导致了我初稿几乎都是借鉴和GPT生成，后被戴老师全部弃用。写完初稿后，戴老师开始了他的修改，基于我的idea，他讲述了一个完全不同的科研探索过程，提出了他自己的一套理论，虽然都是完成了相同的任务，取得了相同的成果，但是换一个叙述方式之后，这篇文章已经完全不同了，文字当中充满了逻辑性，与原先的可以说是天壤之别。经过十几个夜晚的奋斗，我们完成了全文，并理清了思路，这当中由于我的粗心，多少会闹得戴老师烦心，但是他依旧耐心，为我解惑和指导，回想至此也是感激不尽，我也收益良多，不仅初步学会了写文章的所有流程，还获得了些科研思维。（当时好几天都是七八张4090租着跑实验，最后光速报销，财大气粗的感觉真爽。）\n提交了这一不算丰硕的成果到国际顶级会议，我无比激动，这一段经历也让我初步认识了一篇论文的从零到一，当然，多少有些飘飘然，多少有些膨胀。在实习期间，结识了xinyang，我们都对3DGS感兴趣，都在算法部做数字人，他邀请我跟他一起做高斯数字人的改进，我也是欣然接受。\nGGAvatar-新的磨练 在这之前，我对数字人已经非常熟悉了，在去年做科研的同时，我也高度参与了一位硕士生的毕业论文项目，为他完成了大部分代码和实验。主要就是关于三维人体重建的，对数字人的关注从22年就开始了，见过的工作较多，想着自己有一篇文章的经验，这下算是真正入门了，可以往数字人方向上走走了。\n代码上，已然是轻车熟路了，我能够为xinyang提供一些改进思路，并且确实是work的，虽然一些调参工作比较繁杂，但是代码上的工作只进行了一个月左右，就取得了很大的进步。我们开始写文章、选baseline做实验，与之前的流程类似。\n但是，此次做实验与HC-NeRF不同，HC-NeRF跑baseline很方便，公共数据集也比较多，但Avatar类工作没有太多公共数据集，需要大量的时间来复现baseline、修改代码以实现一些公共task、在这上面花的精力比文章主体模型还要多，同时还要进行大量的可视化对比，图表绘制，大量数据的对齐，在这么多繁杂的任务中，我的粗心更是时不时就将事情搞砸，比如渲染视频的帧乱了，或是FLAME的tracker出bug了，每一步都没有很好地去排查，导致错了才发现要从头再来，且当时没有很好地去反思，频频犯错。\n许多叙述上的词汇不到位、某个baseline渲染出来的角度没对齐，这些细节部分的问题，我总是忽略，导致作品最后显得粗糙，还好xinyang非常注重细节，帮我一起排查审核，不过确实实打实的影响了进度，这些错误其实可以不用犯，要么是原理问题没有钻研清楚，要么是单纯粗心大意，没有进一步检查，这里写下一些复盘后的感想，望与读者共勉：\n在完成多个阶段的任务时，要确保每一阶段都达到要求，不然牵一发而动全身，会浪费很多时间，特别是baseline的复现 对待baseline，不能轻视，我认为要将它的代码也看作研究中的一部分，好好研究，才不容易出错 制作对比图表时，很容易发现问题，发现后要顺藤摸瓜地去排查，而不是自圆其说，敷衍了事 在研究HC-NeRF时体会到的：不要只关注一个实验样本的结果，应该关注整体结果，并从指标中发现问题，这也是发现idea的好机会 最后，用心对待正在参与的每一个科研项目，切不可懒散 结语 本文章文字枯燥、叙述繁琐，读者能看到这里是我莫大荣幸。求学路上定有与我经历相似的朋友，若能在我这篇文章中获得些许经验，那本文也是有了意义，很多道理都是经历过后才能知行合一的，但是若能提前悟出，少走弯路，那是最好。","title":"论文相关经历分享"},{"content":"本文用来记录我遇到的各种奇葩bug，不定时更新 Hugo git config \u0026ndash;global core.autocrlf false, 如果使用Windows和git配置hugo要记得这个，不能修改为CRLF，小心这个warning：LF will be replaced by CRLF the next time Git touches it CUDA 运行3DGS相关代码时出现 CUDA error : illegal memory access 这个问题存在很多争议，这里只讨论3D高斯相关代码中这个问题的情况，我是自己魔改代码时出现的.\n主要问题就是你有数据在cpu上，有数据在gpu上，有的作者喜欢在cpu上渲染（少数），有的喜欢丢到gpu上渲染。\n这个报错最难受的就是无法定位到具体的错误，这个时候可以使用torch.cuda.synchronize()往前一行一行地执行来定位具体错误，也可以直接打印变量的device，然后指定好是用.cpu()还是.cuda().\n新增：这个报错还可能发生在你的光栅化没有正确与你的torch版本和cuda版本对应上的时候，此时：\n使用nvcc -V检查你的cuda版本 使用pip list | grep torch检查你的torch版本是否对应好了cuda版本 删除submodule/diff-gaussian-rasterization/build，然后在/submodule/diff-gaussian-rasterization这个目录下运行 python setup.py install。 以上步骤基本可以解决问题，注意此方法适用于在跑gaussian相关baseline的时候，初次配环境出的错，如果是你后期改代码导致报错了，还是关注你自己写的代码有没有问题吧，或者检查你系统的CUDA版本是不是改变了。\n","permalink":"https://net-maker.github.io/post/debug/","summary":"本文用来记录我遇到的各种奇葩bug，不定时更新 Hugo git config \u0026ndash;global core.autocrlf false, 如果使用Windows和git配置hugo要记得这个，不能修改为CRLF，小心这个warning：LF will be replaced by CRLF the next time Git touches it CUDA 运行3DGS相关代码时出现 CUDA error : illegal memory access 这个问题存在很多争议，这里只讨论3D高斯相关代码中这个问题的情况，我是自己魔改代码时出现的.\n主要问题就是你有数据在cpu上，有数据在gpu上，有的作者喜欢在cpu上渲染（少数），有的喜欢丢到gpu上渲染。\n这个报错最难受的就是无法定位到具体的错误，这个时候可以使用torch.cuda.synchronize()往前一行一行地执行来定位具体错误，也可以直接打印变量的device，然后指定好是用.cpu()还是.cuda().\n新增：这个报错还可能发生在你的光栅化没有正确与你的torch版本和cuda版本对应上的时候，此时：\n使用nvcc -V检查你的cuda版本 使用pip list | grep torch检查你的torch版本是否对应好了cuda版本 删除submodule/diff-gaussian-rasterization/build，然后在/submodule/diff-gaussian-rasterization这个目录下运行 python setup.py install。 以上步骤基本可以解决问题，注意此方法适用于在跑gaussian相关baseline的时候，初次配环境出的错，如果是你后期改代码导致报错了，还是关注你自己写的代码有没有问题吧，或者检查你系统的CUDA版本是不是改变了。","title":"Debug记录"},{"content":"Motivation 本文章用来总结本人在3D视觉研究中遇到的问题，同时给出一些经验，主要与Python，NeRF，3DGS相关。\n本人才疏学浅，只希望大家能够在浏览文章后能够互相学习借鉴。\n适用人员：想要入门科研的本科生、未接触过科研的研一、有着科研热情的所有新手！\n写在前面 本文章没有对具体问题的具体解决方法，更多的是自己的一套方法论，希望可以帮助大家获得一定解决问题的通用能力。\n配置环境常见问题 基本网络问题 一定要梯子！一定要梯子！一定要梯子！\n梯子可以解决99%的pip install和conda install遇到的问题 当然，考虑到一些公司环境，这里还是提供一些github镜像和pip镜像（清华源）以及conda镜像（清华源）\n清华源tuna是一个非常好的项目，偶尔会封禁一些下载流量过大的ip，这个时候可以发邮件向他们申请，回复及时且很友善。\n清华pip源配置命令 参考https://mirrors.tuna.tsinghua.edu.cn/help/pypi/ 临时使用：\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple 你的包 默认使用（pip版本\u0026gt;=10.0.0）\npython -m pip install --upgrade pip pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 清华conda源配置命令 参考https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ 修改你的/home/用户名/.condarc文件，替换为\nchannels: - defaults show_channel_urls: true default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/ 如果没有这个文件，则直接创建，无法创建的windows用户可使用conda config --set show_channel_urls yes\nTorch版本老是对不上或者没有CUDA 很多人都被这个问题折磨过，不过这里给出一个比较通用的解决方案\n首先，明确你需要的torch版本，torchvision版本和你自己的cuda版本nvcc -V 接下来，有多种选择 使用conda安装： conda install pytorch=XXX torchvision=XXX cudatoolkit=XXX -c pytorch` 使用conda的好处是简单、高效，且可以自由选择cuda的版本，不过大多数人的网络可能不支持这么丝滑的下载 使用pytorch官方网站的下载连接，手动下载正确版本：pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 个别较难安装的库，如pytorch3D 这里仅以pytorch3D举例，其实没有太多技巧，主要是进入到这个库的官方github，clone到本地，然后python setup.py install即可，非常方便\n难以编译的库，如OPENPOSE 本人有一段在3090上编译openpose的痛苦经历，虽然openpose这个项目的贡献非常大，但是不得不说，这个库已经过时了，在CUDA11以上的版本非常难编译成功。 这里并不细化到如何编译openpose，而是给出一个通用的方法论：\n准备好你需要的工具： Google，Github的issues，阅读英文论坛的耐心 绝大多数的问题都可以在google搜索后使用github的issue功能自行解决，这是很简单但是很多人无法完成的，不要一味地指望CSDN。 解决所有的warning： 当你编译时碰到了莫名其妙的bug，多看看输出中是否有warning的出现吧！ 输出中会包含解决问题的信息的。 具体问题无法搜索到时，减少搜索的词数，从类似的问题中寻找问题的特性 举个例子，当我编译openpose的时候，报错显示有一个lib并未被定义，由于搜不到任何结果，于是我搜索\u0026rsquo;cmake，xxx未被定义\u0026rsquo;，顺利地解决了这个问题。 To be continue 有问题欢迎探讨！\n科研常见问题 简述 这一节主要讲述我自己的科研经历以及碰到的各种问题，包括其解决方案。我个人是CV偏CG方向，3D视觉，仅供参考\n信息搜集\u0026amp;工具汇总 在这里希望大家能够熟练地利用好已有的工具，不要知难而退，很多工具是能非常大地提升自己的效率的 至于工具推荐，我这里不作过多介绍，可以参考以下博客，也是程序员学习基础技能必备：\n大名鼎鼎的CS自学指南：https://csdiy.wiki/ 国内视觉青年学者论坛：VALSE：https://space.bilibili.com/562085182?spm_id_from=333.337.search-card.all.click 浙大CAD实验室入门手册\u0026amp;大牛科研经验分享：https://github.com/pengsida/learning_research Latex写作教程：https://github.com/guanyingc/latex_paper_writing_tips 各类github总结库：awesome-xxx，比如awesome-nerf，awesome-3dgs AI热度排行榜：https://paperswithcode.com/ 文献调研神器：https://www.connectedpapers.com/ 写作神器：https://www.grammarly.com/ AI会议倒计时：https://aideadlin.es/ 文献管理：https://readpaper.com/ 上面提到的大多数教程都是github上的，这里也强烈推荐使用学好git，玩起github，能接触到更多适合你的资源。\n还有更多优质的网站欢迎分享\n代码改了没效果，idea不work？ 相信大多数人刚接触科研的时候和我一样，想到了一个自我感觉良好的idea，然后开始投入代码之中，在失败后频繁地摆弄这一团已经改得乱七八糟的代码，在一遍遍的自我怀疑中丧失科研的信心。\n或许有少数天赋异禀的同学能够避免这个过程，直接发表不错的作品，但是我想说，陷入这个问题的同学也不用气馁，很多人都是这样过来的。 这里，我给出自己的一些建议，能够帮助大家避免陷入这个自我怀疑的过程。\n做好版本控制和实验数据的记录 每天工作完，或是改完一版较为完成的代码，都要git commit一下， 未来的你会感谢每一个commit，特别是赶实验的时候。 做实验不要局限于一个样本 可能是计算机专业（或是NeRF方向）的专属问题，很多人喜欢只看一个样本（scene）的指标，来断定自己的模型好不好，但是这是一个非常严重的错误。即使实验时间非常久，也要做好完成的实验，观察各个指标的变化，通过指标的含义去分析你的实验结果。 拿NeRF的实验举例：你的模型可能没有对PSNR进行提升，但是可能对SSIM这个指标有很大提升，这也是完全有可能的。 选baseline的时候，要懂得知难而退 如果你的领域突然出现了一个很牛逼的作品，而你准备在这个作品的基础上进行改进时，先评估它的代码复杂度、idea需要开发的时间、以及实验的时间和金钱成本。 技术发展是非常快的，控制好时间成本也是科研的硬能力，如果这个作品的实现非常复杂，要么换一个idea，要么等其他开源的简单版本复现。（针对科研新手，大佬可以忽略） 本人曾经便陷入过这个陷阱之中，在Instant-NGP的代码基础上开发一个idea，在代码的海洋中好不容易实现了功能，结果渲染部分无法对齐，debug？ 渲染部分上万行CUDA代码，编译一次需要十几分钟。 最后只能不了了之。 idea不work还是你的代码不work？ 科研写代码可以写得很杂乱，但是细节部分是一定要仔细检查核对的，有时候并不是你的idea不work，而是在某个细节部分你和baseline不一样，从而导致了巨大的差异。 例如：在三维重建任务中，使用softplus激活函数的方法的指标会比使用relu的高。 又比如：它的作品用了float64，而你的是float16，你的部分梯度直接消失了。 这里同样凸显了版本控制的必要性！ 实在做不出来，不如出去走走 可能有不少人在科研路上不断和自己较劲，不达到自己的预期绝不停手。 但是，科研的路还长，一时的得失并不能代表什么，没有成果产出的时候不如出去走走，运动，享受美食或是游戏。 地球缺了这一篇文章并不会停止转动，计算机学科更不会缺我这一份工作，我个人更愿意将生活排在科研前面，享受生活也享受科研。 To be continue 后续的想起来再加，我要去洗澡了！ 写作对我来说太难了！ 没事，对我来说也一样难，那不也得写吗？不让你指望它自己写好？用好我提供的工具，基本的叙述应该是没问题的。\n对我来说，写作的部分可以讲的经验不多，但是上面提供的资料中有大量的写作技巧和教程，大家共勉。\n后续有更多tips，再分享在这。\n","permalink":"https://net-maker.github.io/post/3d-experience/","summary":"Motivation 本文章用来总结本人在3D视觉研究中遇到的问题，同时给出一些经验，主要与Python，NeRF，3DGS相关。\n本人才疏学浅，只希望大家能够在浏览文章后能够互相学习借鉴。\n适用人员：想要入门科研的本科生、未接触过科研的研一、有着科研热情的所有新手！\n写在前面 本文章没有对具体问题的具体解决方法，更多的是自己的一套方法论，希望可以帮助大家获得一定解决问题的通用能力。\n配置环境常见问题 基本网络问题 一定要梯子！一定要梯子！一定要梯子！\n梯子可以解决99%的pip install和conda install遇到的问题 当然，考虑到一些公司环境，这里还是提供一些github镜像和pip镜像（清华源）以及conda镜像（清华源）\n清华源tuna是一个非常好的项目，偶尔会封禁一些下载流量过大的ip，这个时候可以发邮件向他们申请，回复及时且很友善。\n清华pip源配置命令 参考https://mirrors.tuna.tsinghua.edu.cn/help/pypi/ 临时使用：\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple 你的包 默认使用（pip版本\u0026gt;=10.0.0）\npython -m pip install --upgrade pip pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 清华conda源配置命令 参考https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ 修改你的/home/用户名/.condarc文件，替换为\nchannels: - defaults show_channel_urls: true default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/ 如果没有这个文件，则直接创建，无法创建的windows用户可使用conda config --set show_channel_urls yes","title":"2年来3D视觉科研总结\u0026科研经验分享"},{"content":"Hello,My name is WJX\n","permalink":"https://net-maker.github.io/about/","summary":"Hello,My name is WJX","title":"About"}]